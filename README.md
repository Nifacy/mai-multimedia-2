# Лабораторные работы по предмету "Методы, средства и технологии мультимедиа" МАИ

- **Выполнил:** Гришин Алексей Юрьевич
- **Группа:** М8О-408Б-21

## Структура репозитория

Каждой лабораторной работе соответствует jupyter notebook `lab-{n}.ipynb`,
где `n` - номер лабораторной работы соответственно.

Каждый Jupyter notebook разделен заголовками на 4 части:
- Выбор начальных условий
- Создание бейзлайна и оценка качества
- Улучшение бейзлайна
- Имплементация алгоритма машинного обучения

Каждая из таких частей заголовками разделена на пункты, в рамках
который выполнялась текущая лабораторная работа.

Итого, полная структура ноутбуков выглядит следующим образом:

- Название лабораторной работы
  - Подключение вспомогательных библиотек
  - Выбор начальных условий
    - Выбор датасета (только для ЛР 6)
    - Выбор метрик
  - Создание бейзлайна и оценка качества
    - Обучение модели CNN (только для ЛР 6 и 7)
    - Обучение трансформерной модели (только для ЛР 6 и 7)
  - Улучшение бейзлайна
    - "Гипотеза 1"
    - "Гипотеза 2"
    - ...
  - Имплементация алгоритма машинного обучения
    - Сверточная модель (только для ЛР 6 и 7)
    - Трансформерная модель (только для ЛР 6 и 7)
    - Сравнение с бейзлайном
    - Сравнение с улучшенным бейзлайном

# Подведение итогов

## Классификация

| Модель                                               | Accuracy | Precision | Recall | F1-Score |
|------------------------------------------------------|----------|-----------|--------|----------|
| Бейзлайн (CNN)                                       | 0.7284   | 0.7254    | 0.7284 | 0.7268   |
| Улучшенный бейзлайн (CNN)                            | 0.8457   | 0.8354    | 0.8501 | 0.8427   |
| Бейзлайн (трансформер)                               | 0.7321   | 0.7012    | 0.7427 | 0.7213   |
| Улучшенный бейзлайн (трансформер)                    | 0.8352   | 0.8259    | 0.8401 | 0.8329   |
| Бейзлайн (собственная имплементация, CNN)            | 0.3295   | 0.2218    | 0.2195 | 0.2206   |
| Улучшенный бейзлайн (собственная имплементация, CNN) | 0.6046   | 0.2555    | 0.5046 | 0.3392   |
| Бейзлайн (собственная имплементация, трансформер)    | 0.3854   | 0.2153    | 0.2854 | 0.2454   |
| Бейзлайн (собственная имплементация, трансформер)    | 0.6527   | 0.3862    | 0.3927 | 0.3894   |

## Семантическая сегментация

| Модель                                               | IoU    |
|------------------------------------------------------|--------|
| Бейзлайн (CNN)                                       | 0.3154 |
| Улучшенный бейзлайн (CNN)                            | 0.4123 |
| Бейзлайн (трансформер)                               | 0.3557 |
| Улучшенный бейзлайн (трансформер)                    | 0.3042 |
| Бейзлайн (собственная имплементация, CNN)            | 0.2034 |
| Улучшенный бейзлайн (собственная имплементация, CNN) | 0.2157 |
| Бейзлайн (собственная имплементация, трансформер)    | 0.1532 |
| Бейзлайн (собственная имплементация, трансформер)    | 0.2078 |

## Обнаружение и распознование объектов

| Модель                                          | mAP50  | mAP50-95 |
|-------------------------------------------------|--------|----------|
| Бейзлайн (YOLO)                                 | 0.299  | 0.274    |
| Улучшенный бейзлайн (YOLO)                      | 0.27   | 0.242    |
| Бейзлайн (собственная имплементация)            | 0.1965 | 0.2218   |
| Улучшенный бейзлайн (собственная имплементация) | 0.1852 | 0.2034   |

# Выводы по метрикам

## Классификация

### CNN

- Улучшенный бейзлайн показал значительный прирост по всем метрикам по 
  сравнению с изначальным бейзлайном: значение метрики "Accuracy"
  выросло с $0.7284$ до $0.8457$, F1-Score - с $0.7268$ до $0.8427$,
  что свидетельствует о существенном улучшении качества модели;

- Собственная имплементация показала значительно худшие результаты по 
  сравнению с официальным бейзлайном: значение метрики "Accuracy" около $0.33$ для изначальной и $0.60$ для улучшенной версии, при этом значения
  метрик "Precision" и "Recall" остаются низкими. Обосновано это упрощенной
  архитектурой модели и тем, что модель обучалась с нуля, а не была
  предобученной;

- Несмотря на улучшение собственной имплементации, она всё ещё
  уступает официальному бейзлайну по всем метрикам.

### Трансформеры

- Улучшенный бейзлайн на основе трансформера продемонстрировал заметный 
  рост метрик по сравнению с изначальным бейзлайном: значение метрики 
  "Accuracy" повысилось с $0.7321$ до $0.8352$, F1-Score - с $0.7213$ до
  $0.8329$;

- Собственная имплементация трансформера показала более низкие показатели
  в изначальной версии, но улучшенная версия достигла accuracy $0.6527$, 
  что лучше, чем изначальная, но всё ещё ниже чем у предобученной модели;

- Метрики "Precision" и "Recall" собственной реализации трансформера 
  остаются на низком уровне по сравнению с предобученной моделью.

## Семантическая сегментация

### CNN

- Улучшенный оказал положительное влияние на качестве сегментации для
  сверточной модели CNN, о чем свидетельствует рост показаний метрики IoU 
  с $0.3154$ до $0.4123$;

- По сравнению с другими реализациями моделей на разных бейзлайнах
  модель CNN, обученная на улучшенном бейзлайне, показала самые лучшие
  результаты, если опираться на показания метрики IoU;

- Собственная имплементация архитектуры CNN показала немного
  хуже результаты по сравнению с моделью UNet. На обычном бейзлайне
  значение метрики IoU достигло значений $0.2034$, а на улучшенном - 
  значения $0.2157$. Связано это может быть с более простой архитектурой
  и отсутствием предобучения, в отличие от UNet;

### Трансформеры

- Модель Segformer показала на бейзлайне значение метрики IoU $0.3557$,
  что выше, чем у собственной реализации, но ниже, чем у улучшенного 
  бейзлайна CNN;

- Улучшенный бейзлайн продемонстрировал снижение метрики IoU до $0.3042$
  для модели Segformer;

- Собственная имплементация трансформерной модели показала
  результаты, более низкие по сравнению с моделью Segformer.
  При обучении на бейзлайне метрика IoU достигла значения $0.1532$,
  а на улучшенном - значения $0.2078$.

## Обнаружение и распознавание объектов

- Модель Yolov11s продемонстрировала неплохие результаты при обучении на
  бейзлайне. Метрика "mAP50" достигла значения $0.299$, а метрика
  "mAP50-95" - значения $0.274$, что является вполне хорошим результатом
  с учётом количества предсказываемых классов;

- При обучении модели YOLO на улучшенном бейзлайне стали видны
  снижения показаний метрик "mAP" и "mAP50-95" до значений $0.27$
  и $0.242$ соответственно;

- Собственная реализация алгоритма машинного обучения показала
  более низкие результаты. Метрика "mAP50" достигла значений $0.1965$
  при обучении модели на бейзлайне и значения $0.1852$ при обучении 
  на его улучшенной версии. Метрика же "mAP50-95" достигла значений
  $0.2218$ и $0.2034$. Такие результаты могут быть обоснованы
  упрощенной реализацией и отсутствием предобучения;

# Общий вывод

- Гипотезы, использованные для улучшения бейзлайна, оказали
  положительный эффект на качество моделей почти во всех рассмотренных задачах: в некоторых задачах улучшилось качество моделей CNN, а в некоторых - трансформерной модели. Исключением является только модель
  семейства YOLO, которая обучалась для решения задачи обнаружения объектов;

- Собственные реализации моделей в целом уступают предобученным
  моделям, таким как ResNet18 и UNet. Это связано с более простой 
  архитектурой, отсутствием предобучения;

- Среди различных архитектур и подходов CNN-модели на улучшенных
  бейзлайнах обычно демонстрировали лучшие результаты в задачах 
  классификации и сегментации. Трансформерные же модели показывают
  потенциал, но требуют больше ресурсов для обучения (в том числе и
  временных).
